{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f267b9a7",
   "metadata": {},
   "source": [
    "# **提示链模式概述**\n",
    "  - 提示链也称为流水线模式，用于处理复杂任务，通过将问题分解为多个子问题，逐步解决。\n",
    "  - 每个子问题通过专门设计的提示处理，输出作为下一个提示的输入。\n",
    "  - 提示链提高了模块化和清晰度，增强了处理过程的稳定性和可解释性。\n",
    "  - 支持与外部知识、工具、API等交互，扩展了LLM的能力。\n",
    "  - 适合构建能够自主规划、推理和动态应对环境的智能代理。\n",
    "\n",
    "- **单个提示的局限性**\n",
    "  - 复杂任务用单一提示容易导致模型难以处理约束和指令。\n",
    "  - 潜在的指令忽略、上下文漂移和认知负荷增加，降低准确性和可靠性。\n",
    "  - 例如，长篇总结或多任务分析会出现响应不准确或信息缺失。\n",
    "\n",
    "- **通过顺序分解增强可靠性**\n",
    "  - 将复杂任务分解为多个步骤，每步专注于特定子任务。\n",
    "  - 例如市场研究报告总结分为：总结关键发现 → 识别趋势和数据点 → 编写简明邮件。\n",
    "  - 每步简化认知负担，提升准确度和可靠性。\n",
    "  - 每步可分配不同角色，明确职责。\n",
    "\n",
    "- **结构化输出的重要性**\n",
    "  - 保障步骤间数据传递的完整性。\n",
    "  - 使用JSON或XML等结构化格式避免歧义和格式错误。\n",
    "  - 示例中用JSON格式表示趋势及其支持数据。\n",
    "  - 结构化数据可被精确解析并传递到后续步骤，减少错误。\n",
    "\n",
    "- **整体效益**\n",
    "  - 通过提示链，提升多步任务的准确性、可控性和鲁棒性。\n",
    "  - 有助于构建复杂、多功能的AI应用和智能代理系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f334c0",
   "metadata": {},
   "source": [
    "例如，趋势识别步骤的输出可以格式化为 JSON 对象：\n",
    "```json\n",
    "{\n",
    "  \"trends\": [\n",
    "    {\n",
    "      \"trend_name\": \"AI驱动的个性化\",\n",
    "      \"supporting_data\": \"73%的消费者更愿意与品牌合作\"\n",
    "    },\n",
    "    {\n",
    "      \"trend_name\": \"可持续和道德品牌\",\n",
    "      \"supporting_data\": \"带有ESG相关声明的产品销量增长了28%\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93bc0aa",
   "metadata": {},
   "source": [
    "## 实用应用与用例总结\n",
    "\n",
    "- **信息处理工作流**\n",
    "  - 分步骤处理原始信息，如文档摘要、关键实体提取、数据库查询和报告生成。\n",
    "  - 适用于自动内容分析、AI驱动的研究助手和复杂报告生成。\n",
    "\n",
    "- **复杂查询应答**\n",
    "  - 分解复杂问题，逐步检索和推理，实现多步骤综合回答。\n",
    "  - 适合多源信息融合、多任务推理的AI系统。\n",
    "\n",
    "- **数据提取与转化**\n",
    "  - 将非结构化文本转成结构化数据，通过迭代过程校验和完善。\n",
    "  - 适用场景包括表单、发票、邮件数据抽取和OCR问题处理。\n",
    "  - 结合数学计算与外部计算工具，提升准确率。\n",
    "\n",
    "- **内容生成工作流**\n",
    "  - 按相位分解复杂内容的创作过程，包含选题、写作和审校。\n",
    "  - 支持创意叙事、技术文档及结构化文本生成。\n",
    "\n",
    "- **带状态的对话代理**\n",
    "  - 通过链式提示构建上下文，维护多轮对话的连贯性与上下文记忆。\n",
    "  - 支持意图识别、状态更新和持续对话管理。\n",
    "\n",
    "- **代码生成与改进**\n",
    "  - 将代码任务拆解成离散步骤，如伪代码生成、代码初稿、错误排查和文档编写。\n",
    "  - 适合AI辅助软件开发，通过模块化降低复杂度。\n",
    "\n",
    "- **多模态与多步骤推理**\n",
    "  - 分解多模态数据（如图像和表格）中的信息处理任务。\n",
    "  - 结合图像文字提取、标签联系及表格式信息解释，实现综合理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93a646",
   "metadata": {},
   "source": [
    "## 实践示例\n",
    "\n",
    "```\n",
    "pip install langchain langchain-community langchain-openai langgraph\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4fada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000020F6516CF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000020F6516D310>, root_client=<openai.OpenAI object at 0x0000020F6516C410>, root_async_client=<openai.AsyncOpenAI object at 0x0000020F6516D090>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://127.0.0.1:1234/v1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the Language Model (using ChatOpenAI is recommended)\n",
    "llm = ChatOpenAI(base_url=\"http://127.0.0.1:1234/v1\", temperature=0, api_key=\"not-needed\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2fe2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text_input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text_input'], input_types={}, partial_variables={}, template='Extract the technical specifications from the following text:\\n\\n{text_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Prompt 1: Extract Information ---\n",
    "\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "    \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")\n",
    "\n",
    "prompt_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969a570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt 2: Transform to JSON ---\n",
    "\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "    \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5579c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text_input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text_input'], input_types={}, partial_variables={}, template='Extract the technical specifications from the following text:\\n\\n{text_input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000020F6516CF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000020F6516D310>, root_client=<openai.OpenAI object at 0x0000020F6516C410>, root_async_client=<openai.AsyncOpenAI object at 0x0000020F6516D090>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://127.0.0.1:1234/v1')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Build the Chain using LCEL ---\n",
    "# The StrOutputParser() converts the LLM's message output to a simple string.\n",
    "\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "extraction_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34bf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full chain passes the output of the extraction chain into the 'specifications'\n",
    "# variable for the transformation prompt.\n",
    "\n",
    "full_chain = (\n",
    "    {\"specifications\": extraction_chain}\n",
    "    | prompt_transform\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f4185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "<think>\n",
      "```json\n",
      "{\n",
      "  \"cpu\": \"3.5 GHz octa-core processor\",\n",
      "  \"memory\": \"16GB of RAM\",\n",
      "  \"storage\": \"1TB NVMe SSD\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# --- Run the Chain ---\n",
    "\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "\n",
    "# Execute the chain with the input text dictionary.\n",
    "\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934965a2",
   "metadata": {},
   "source": [
    "这段 Python 代码演示了如何使用 LangChain 库来处理文本。它利用了两个独立的提示：一个从输入字符串中提取技术规格，另一个将这些规格格式化为 JSON 对象。ChatOpenAI 模型被用来与语言模型进行交互，StrOutputParser 确保输出是可直接使用的字符串格式。LangChain 表达式语言（LCEL），也就是代码中的 | 符号，被用来优雅地将这些组件「链接」在一起。代码首先构建了一个 extraction_chain，负责提取规格。然后，full_chain 接收前一个链的输出，并将其作为输入传给负责转换格式的提示。最后，我们提供了一段描述笔记本电脑的示例文本，并通过 invoke 方法让 full_chain 按顺序执行这两个步骤，打印出最终提取并格式化好的 JSON 字符串。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27bc08",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
